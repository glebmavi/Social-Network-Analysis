{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unlike-harvest"
   },
   "source": [
    "# Классификация текстов\n",
    "В этом ноутбуке ваша задача будет разобраться с классификацией твитов на русском языке на позитивные и негативные."
   ],
   "id": "unlike-harvest"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vocal-depression"
   },
   "source": [
    "Для начала подготовим датасет к чтению:"
   ],
   "id": "vocal-depression"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "MMiT7tvPxC1r",
    "outputId": "fab9a389-e221-4ab6-f534-95496861e51e",
    "ExecuteTime": {
     "end_time": "2024-09-18T08:18:27.079946Z",
     "start_time": "2024-09-18T08:18:27.025551Z"
    }
   },
   "source": [
    "!gdown --id 1GujrcFzRdo3E7UtUkcrljzDS9czBBy3s\n",
    "!gdown --id 1vvm-PrV0r2wuGbYYovZSuReYOXpu0JRK\n",
    "\n",
    "import os, shutil\n",
    "if not os.path.exists('/content/data'):\n",
    "  os.makedirs('/content/data')\n",
    "shutil.move('train.csv', \"/content/data\")\n",
    "shutil.move('val.csv', \"/content/data\")"
   ],
   "id": "MMiT7tvPxC1r",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gdown' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'gdown' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/content/data\\\\val.csv'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0\n",
    "!pip install -q torchtext==0.12.0\n",
    "!pip install -q torchdata==0.3.0"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xLRD2YdSk2n",
    "outputId": "1822fb91-ce74-42c1-acba-796a957d74dd"
   },
   "id": "6xLRD2YdSk2n",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m750.6/750.6 MB\u001B[0m \u001B[31m1.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.0/21.0 MB\u001B[0m \u001B[31m28.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.9/2.9 MB\u001B[0m \u001B[31m34.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.11.0 which is incompatible.\n",
      "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.11.0 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.4/10.4 MB\u001B[0m \u001B[31m32.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m47.7/47.7 KB\u001B[0m \u001B[31m2.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "engaging-cancellation"
   },
   "source": [
    "from csv import reader\n",
    "\n",
    "def dataset_iter(part):\n",
    "    with open(\"data/\" + part + \".csv\", \"rt\", newline=\"\") as f_in:\n",
    "        r = reader(f_in)\n",
    "        next(r)\n",
    "        while r:\n",
    "            try: \n",
    "                _, text, cls = next(r)\n",
    "                yield cls, text\n",
    "            except StopIteration:\n",
    "                return"
   ],
   "id": "engaging-cancellation",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "american-commercial"
   },
   "source": [
    "def dataset_rows_num(part):\n",
    "    with open(\"data/\" + part + \".csv\", \"rt\") as f_in:\n",
    "        rows_num = len(f_in.readlines()) - 1\n",
    "    return rows_num"
   ],
   "id": "american-commercial",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "class RawTextIterableDataset(IterableDataset):\n",
    "    \"\"\"Простой итератор по текстовому набору данных.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, full_num_lines, current_pos, iterator):\n",
    "        \"\"\"Конструктор\n",
    "        \"\"\"\n",
    "        super(RawTextIterableDataset, self).__init__()\n",
    "        self.full_num_lines = full_num_lines\n",
    "        self._iterator = iterator\n",
    "        self.num_lines = full_num_lines\n",
    "        self.current_pos = current_pos\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_pos == self.num_lines - 1:\n",
    "            raise StopIteration\n",
    "        item = next(self._iterator)\n",
    "        if self.current_pos is None:\n",
    "            self.current_pos = 0\n",
    "        else:\n",
    "            self.current_pos += 1\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_lines\n",
    "\n",
    "    def pos(self):\n",
    "        \"\"\"\n",
    "        Возвращает текущую позицию в наборе данных.\n",
    "        \"\"\"\n",
    "        return self.current_pos\n",
    "\n"
   ],
   "metadata": {
    "id": "dUKNJFtpDZQj"
   },
   "id": "dUKNJFtpDZQj",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "considered-stretch"
   },
   "source": [
    "def RU_TW(part):\n",
    "    return RawTextIterableDataset(dataset_rows_num(part), 0, dataset_iter(part))"
   ],
   "id": "considered-stretch",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final-psychology"
   },
   "source": [
    "Теперь сделаем словарь:"
   ],
   "id": "final-psychology"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "french-chick"
   },
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter, OrderedDict\n",
    "from torchtext.vocab import vocab as _vocab\n",
    "\n",
    "tokenizer = get_tokenizer('toktok', 'ru')\n",
    "train_iter = RU_TW(\"train\")\n",
    "counter = Counter()\n",
    "for (label, line) in train_iter:\n",
    "    counter.update(tokenizer(line))\n",
    "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "\n",
    "unk_token = '<unk>'\n",
    "vocab = _vocab(ordered_dict, min_freq=1000, specials=[unk_token])\n",
    "vocab.set_default_index(vocab[unk_token])\n"
   ],
   "id": "french-chick",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "finished-heading"
   },
   "source": [
    "Зададим функции предобработки датасета:"
   ],
   "id": "finished-heading"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "offensive-orbit"
   },
   "source": [
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "label_pipeline = lambda x: int(x)"
   ],
   "id": "offensive-orbit",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "republican-salem"
   },
   "source": [
    "Сделаем загрузчик датасета (на жаргоне \"батчеварку\"):"
   ],
   "id": "republican-salem"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "transsexual-comment"
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "train_iter = RU_TW(\"train\")\n",
    "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ],
   "id": "transsexual-comment",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dangerous-sapphire"
   },
   "source": [
    "Пришло время сделать модель для классификации. Вот ее графическое изображение:\n",
    "<img src=\"https://pytorch.org/tutorials/_images/text_sentiment_ngrams_model.png\" width=\"800\" height=\"400\">"
   ],
   "id": "dangerous-sapphire"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "published-start"
   },
   "source": [
    "А вот код:"
   ],
   "id": "published-start"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "shaped-serbia"
   },
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ],
   "id": "shaped-serbia",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "israeli-arrival"
   },
   "source": [
    "Создадим объект модели:"
   ],
   "id": "israeli-arrival"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "annual-migration"
   },
   "source": [
    "train_iter = RU_TW(\"train\")\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 4\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ],
   "id": "annual-migration",
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mineral-patrol"
   },
   "source": [
    "Зададим функции тренировки и проверки модели:"
   ],
   "id": "mineral-patrol"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "invisible-moderator"
   },
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = model(text, offsets)\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()"
   ],
   "id": "invisible-moderator",
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "insured-possession"
   },
   "source": [
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ],
   "id": "insured-possession",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "recorded-montreal"
   },
   "source": [
    "Наконец, обучение:"
   ],
   "id": "recorded-montreal"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "amended-transfer",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7fa76b19-83c1-43b1-877b-5f6eaf3351b8"
   },
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "# Hyperparameters\n",
    "EPOCHS = 1 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_iter = RU_TW(\"train\")\n",
    "test_iter = RU_TW(\"val\")\n",
    "train_dataset = list(train_iter)\n",
    "test_dataset = list(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ],
   "id": "amended-transfer",
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "| epoch   1 |   500/ 2694 batches | accuracy    0.544\n",
      "| epoch   1 |  1000/ 2694 batches | accuracy    0.580\n",
      "| epoch   1 |  1500/ 2694 batches | accuracy    0.585\n",
      "| epoch   1 |  2000/ 2694 batches | accuracy    0.595\n",
      "| epoch   1 |  2500/ 2694 batches | accuracy    0.593\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 27.88s | valid accuracy    0.570 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upset-strain"
   },
   "source": [
    "И проверка:"
   ],
   "id": "upset-strain"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "surgical-burton",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "46f39277-ed38-45af-feea-7e3d8226d859"
   },
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ],
   "id": "surgical-burton",
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.571\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alpine-thing"
   },
   "source": [
    "А также финальная, т.н. ручная проверка. Здесь можно задать любой текст, который вы хотите проверить:"
   ],
   "id": "alpine-thing"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fantastic-introduction",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ec47cf52-49c9-4ddf-91c0-d2450d2307ee"
   },
   "source": [
    "ag_news_label = {0: \"Negative\",\n",
    "                 1: \"Positive\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item()\n",
    "\n",
    "ex_text_str = \"привет\"\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "print(\"This is a %s twit\" %ag_news_label[predict(ex_text_str, text_pipeline)])"
   ],
   "id": "fantastic-introduction",
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This is a Positive twit\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accompanied-particle"
   },
   "source": [
    "### Ваша задача состоит в том, чтобы улучшить качество модели на представленных данных. Все-таки 57% - это немногим лучше слепого угадывания ответа."
   ],
   "id": "accompanied-particle"
  }
 ]
}
