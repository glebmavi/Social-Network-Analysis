{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unlike-harvest"
   },
   "source": [
    "# Классификация текстов\n",
    "В этом ноутбуке ваша задача будет разобраться с классификацией твитов на русском языке на позитивные и негативные."
   ],
   "id": "unlike-harvest"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vocal-depression"
   },
   "source": [
    "Для начала подготовим датасет к чтению:"
   ],
   "id": "vocal-depression"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "MMiT7tvPxC1r",
    "outputId": "fab9a389-e221-4ab6-f534-95496861e51e",
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:08.956768Z",
     "start_time": "2024-09-18T09:27:08.946759Z"
    }
   },
   "source": [
    "import os\n",
    "import shutil\n",
    "import gdown\n",
    "\n",
    "# Define the source and destination paths\n",
    "source_files = ['train.csv', 'val.csv']\n",
    "destination_dir = os.path.join('.', 'data')\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Check if files exist in the destination directory\n",
    "for file in source_files:\n",
    "    dest_file_path = os.path.join(destination_dir, file)\n",
    "    if not os.path.exists(dest_file_path):\n",
    "        # Download the file if it does not exist\n",
    "        if file == 'train.csv':\n",
    "            gdown.download(id=\"1GujrcFzRdo3E7UtUkcrljzDS9czBBy3s\", output=file, quiet=False)\n",
    "        elif file == 'val.csv':\n",
    "            gdown.download(id=\"1vvm-PrV0r2wuGbYYovZSuReYOXpu0JRK\", output=file, quiet=False)\n",
    "        \n",
    "        # Move the file to the destination directory\n",
    "        if os.path.exists(file):\n",
    "            shutil.move(file, destination_dir)\n",
    "        else:\n",
    "            print(f\"File {file} does not exist.\")\n",
    "    else:\n",
    "        print(f\"File {file} already exists in the destination directory.\")"
   ],
   "id": "854011be4814b068",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File train.csv already exists in the destination directory.\n",
      "File val.csv already exists in the destination directory.\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:11.363790Z",
     "start_time": "2024-09-18T09:27:09.010161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%pip install torch==2.2.2\n",
    "%pip install torchtext==0.17.2"
   ],
   "id": "ec8ee380ce56835e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.2.2 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from torch==2.2.2) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from torch==2.2.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from torch==2.2.2) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from torch==2.2.2) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from torch==2.2.2) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from torch==2.2.2) (2024.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from jinja2->torch==2.2.2) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchtext==0.17.2 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: tqdm in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from torchtext==0.17.2) (4.66.5)\n",
      "Requirement already satisfied: requests in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from torchtext==0.17.2) (2.32.3)\n",
      "Requirement already satisfied: torch==2.2.2 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from torchtext==0.17.2) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from torchtext==0.17.2) (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from torch==2.2.2->torchtext==0.17.2) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from torch==2.2.2->torchtext==0.17.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from torch==2.2.2->torchtext==0.17.2) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from torch==2.2.2->torchtext==0.17.2) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from torch==2.2.2->torchtext==0.17.2) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from torch==2.2.2->torchtext==0.17.2) (2024.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from requests->torchtext==0.17.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from requests->torchtext==0.17.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from requests->torchtext==0.17.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from requests->torchtext==0.17.2) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from tqdm->torchtext==0.17.2) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from jinja2->torch==2.2.2->torchtext==0.17.2) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from sympy->torch==2.2.2->torchtext==0.17.2) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "engaging-cancellation",
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:11.376551Z",
     "start_time": "2024-09-18T09:27:11.364814Z"
    }
   },
   "source": [
    "from csv import reader\n",
    "\n",
    "def dataset_iter(part):\n",
    "    with open(\"data/\" + part + \".csv\", \"rt\", newline=\"\") as f_in:\n",
    "        r = reader(f_in)\n",
    "        next(r)\n",
    "        while r:\n",
    "            try: \n",
    "                _, text, cls = next(r)\n",
    "                yield cls, text\n",
    "            except StopIteration:\n",
    "                return"
   ],
   "id": "engaging-cancellation",
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "american-commercial",
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:11.381450Z",
     "start_time": "2024-09-18T09:27:11.376551Z"
    }
   },
   "source": [
    "def dataset_rows_num(part):\n",
    "    with open(\"data/\" + part + \".csv\", \"rt\") as f_in:\n",
    "        rows_num = len(f_in.readlines()) - 1\n",
    "    return rows_num"
   ],
   "id": "american-commercial",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Got error:\n",
    "```\n",
    "A module that was compiled using NumPy 1.x cannot be run in\n",
    "NumPy 2.1.1 as it may crash. To support both 1.x and 2.x\n",
    "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
    "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
    "\n",
    "If you are a user of the module, the easiest solution will be to\n",
    "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
    "We expect that some modules will need time to support NumPy 2.\n",
    "```\n",
    "Therefore downgrade numpy:"
   ],
   "id": "154c3ff8492445b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:12.394603Z",
     "start_time": "2024-09-18T09:27:11.381450Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install \"numpy<2.0\"",
   "id": "20298d2ffb30086b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2.0 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "class RawTextIterableDataset(IterableDataset):\n",
    "    \"\"\"Простой итератор по текстовому набору данных.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, full_num_lines, current_pos, iterator):\n",
    "        \"\"\"Конструктор\n",
    "        \"\"\"\n",
    "        super(RawTextIterableDataset, self).__init__()\n",
    "        self.full_num_lines = full_num_lines\n",
    "        self._iterator = iterator\n",
    "        self.num_lines = full_num_lines\n",
    "        self.current_pos = current_pos\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_pos == self.num_lines - 1:\n",
    "            raise StopIteration\n",
    "        item = next(self._iterator)\n",
    "        if self.current_pos is None:\n",
    "            self.current_pos = 0\n",
    "        else:\n",
    "            self.current_pos += 1\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_lines\n",
    "\n",
    "    def pos(self):\n",
    "        \"\"\"\n",
    "        Возвращает текущую позицию в наборе данных.\n",
    "        \"\"\"\n",
    "        return self.current_pos\n",
    "\n"
   ],
   "metadata": {
    "id": "dUKNJFtpDZQj",
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:12.398736Z",
     "start_time": "2024-09-18T09:27:12.394603Z"
    }
   },
   "id": "dUKNJFtpDZQj",
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "considered-stretch",
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:12.404981Z",
     "start_time": "2024-09-18T09:27:12.398736Z"
    }
   },
   "source": [
    "def RU_TW(part):\n",
    "    return RawTextIterableDataset(dataset_rows_num(part), 0, dataset_iter(part))"
   ],
   "id": "considered-stretch",
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final-psychology"
   },
   "source": [
    "Теперь сделаем словарь:"
   ],
   "id": "final-psychology"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:13.437683Z",
     "start_time": "2024-09-18T09:27:12.404981Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install nltk",
   "id": "d7dbebb6e51250c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\imprimir\\3kurs\\5sem\\socmedana\\task2\\task2\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "french-chick",
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:17.400547Z",
     "start_time": "2024-09-18T09:27:13.437683Z"
    }
   },
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter, OrderedDict\n",
    "from torchtext.vocab import vocab as _vocab\n",
    "\n",
    "tokenizer = get_tokenizer('toktok', 'ru')\n",
    "train_iter = RU_TW(\"train\")\n",
    "counter = Counter()\n",
    "for (label, line) in train_iter:\n",
    "    counter.update(tokenizer(line))\n",
    "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "\n",
    "unk_token = '<unk>'\n",
    "vocab = _vocab(ordered_dict, min_freq=1000, specials=[unk_token])\n",
    "vocab.set_default_index(vocab[unk_token])\n"
   ],
   "id": "french-chick",
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "finished-heading"
   },
   "source": [
    "Зададим функции предобработки датасета:"
   ],
   "id": "finished-heading"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "offensive-orbit",
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:17.404803Z",
     "start_time": "2024-09-18T09:27:17.400547Z"
    }
   },
   "source": [
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "label_pipeline = lambda x: int(x)"
   ],
   "id": "offensive-orbit",
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "republican-salem"
   },
   "source": [
    "Сделаем загрузчик датасета (на жаргоне \"батчеварку\"):"
   ],
   "id": "republican-salem"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "transsexual-comment",
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:17.491813Z",
     "start_time": "2024-09-18T09:27:17.404803Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "train_iter = RU_TW(\"train\")\n",
    "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ],
   "id": "transsexual-comment",
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dangerous-sapphire"
   },
   "source": [
    "Пришло время сделать модель для классификации. Вот ее графическое изображение:\n",
    "\n",
    "<img src=\"https://pytorch.org/tutorials/_images/text_sentiment_ngrams_model.png\" width=\"800\" height=\"400\">"
   ],
   "id": "dangerous-sapphire"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "published-start"
   },
   "source": [
    "А вот код:"
   ],
   "id": "published-start"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "shaped-serbia",
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:17.496772Z",
     "start_time": "2024-09-18T09:27:17.491813Z"
    }
   },
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ],
   "id": "shaped-serbia",
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "israeli-arrival"
   },
   "source": [
    "Создадим объект модели:"
   ],
   "id": "israeli-arrival"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "annual-migration",
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:17.763588Z",
     "start_time": "2024-09-18T09:27:17.496772Z"
    }
   },
   "source": [
    "train_iter = RU_TW(\"train\")\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 4\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ],
   "id": "annual-migration",
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mineral-patrol"
   },
   "source": [
    "Зададим функции тренировки и проверки модели:"
   ],
   "id": "mineral-patrol"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "invisible-moderator",
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:17.771022Z",
     "start_time": "2024-09-18T09:27:17.763588Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = model(text, offsets)\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()"
   ],
   "id": "invisible-moderator",
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "insured-possession",
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:17.776576Z",
     "start_time": "2024-09-18T09:27:17.771022Z"
    }
   },
   "source": [
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ],
   "id": "insured-possession",
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "recorded-montreal"
   },
   "source": [
    "Наконец, обучение:"
   ],
   "id": "recorded-montreal"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "amended-transfer",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7fa76b19-83c1-43b1-877b-5f6eaf3351b8",
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:25.670198Z",
     "start_time": "2024-09-18T09:27:17.776576Z"
    }
   },
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "# Hyperparameters\n",
    "EPOCHS = 1 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_iter = RU_TW(\"train\")\n",
    "test_iter = RU_TW(\"val\")\n",
    "train_dataset = list(train_iter)\n",
    "test_dataset = list(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ],
   "id": "amended-transfer",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 2694 batches | accuracy    0.548\n",
      "| epoch   1 |  1000/ 2694 batches | accuracy    0.577\n",
      "| epoch   1 |  1500/ 2694 batches | accuracy    0.586\n",
      "| epoch   1 |  2000/ 2694 batches | accuracy    0.587\n",
      "| epoch   1 |  2500/ 2694 batches | accuracy    0.596\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  7.58s | valid accuracy    0.614 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upset-strain"
   },
   "source": [
    "И проверка:"
   ],
   "id": "upset-strain"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "surgical-burton",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "46f39277-ed38-45af-feea-7e3d8226d859",
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:26.462213Z",
     "start_time": "2024-09-18T09:27:25.670198Z"
    }
   },
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ],
   "id": "surgical-burton",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.617\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alpine-thing"
   },
   "source": [
    "А также финальная, т.н. ручная проверка. Здесь можно задать любой текст, который вы хотите проверить:"
   ],
   "id": "alpine-thing"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fantastic-introduction",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ec47cf52-49c9-4ddf-91c0-d2450d2307ee",
    "ExecuteTime": {
     "end_time": "2024-09-18T09:27:26.471729Z",
     "start_time": "2024-09-18T09:27:26.462213Z"
    }
   },
   "source": [
    "ag_news_label = {0: \"Negative\",\n",
    "                 1: \"Positive\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item()\n",
    "\n",
    "ex_text_str = \"привет\"\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "print(\"This is a %s twit\" %ag_news_label[predict(ex_text_str, text_pipeline)])"
   ],
   "id": "fantastic-introduction",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Positive twit\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accompanied-particle"
   },
   "source": [
    "### Ваша задача состоит в том, чтобы улучшить качество модели на представленных данных. Все-таки 57% - это немногим лучше слепого угадывания ответа."
   ],
   "id": "accompanied-particle"
  }
 ]
}
